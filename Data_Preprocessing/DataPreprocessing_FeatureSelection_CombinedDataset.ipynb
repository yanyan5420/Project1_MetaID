{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_descriptors(data):\n",
    "    '''\n",
    "    This function is to get the descriptors of each SMILES, and get a new data frame\n",
    "    =========\n",
    "    Parameter:\n",
    "    data: DataFrame\n",
    "        a data frame containing metabolites and their corresponding SMILES\n",
    "    =========\n",
    "    \n",
    "    Output: a updated data frame containing descriptors\n",
    "    '''\n",
    "    \n",
    "    for desc, func in Descriptors.descList:\n",
    "        data.loc[:,desc] = data.SMILES.apply(lambda x: func(Chem.MolFromSmiles(x)) if Chem.MolFromSmiles(x) is not None else 'nan')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_std(data, threshold):\n",
    "    '''\n",
    "    This function is to filter descriptors by standard deviations\n",
    "    =========\n",
    "    Parameter:\n",
    "    \n",
    "    data: DataFrame\n",
    "        a data frame containing metabolites and their corresponding descriptors\n",
    "    \n",
    "    threshold: float\n",
    "    =========\n",
    "    \n",
    "    Output: a filtered data frame containing descriptors\n",
    "    '''\n",
    "    \n",
    "    drop_columns = []\n",
    "    \n",
    "    for col in data.columns[6:]:\n",
    "        \n",
    "        if data[col].std() <= threshold:\n",
    "            drop_columns.append(col)\n",
    "    \n",
    "    data.drop(drop_columns, axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removed_correlation(df, feature_list, feature, threshold, remove_list):\n",
    "    '''\n",
    "    This function is to filter descriptors by Pearson correlation\n",
    "    =========\n",
    "    Parameter:\n",
    "    \n",
    "    df: DataFrame\n",
    "        a data frame containing metabolites and their corresponding descriptors\n",
    "    \n",
    "    feature_list: List\n",
    "        the list of features that are filtered by std\n",
    "    \n",
    "    feature: String\n",
    "        a molecular descriptor\n",
    "    \n",
    "    threshold: float\n",
    "    \n",
    "    remove_list: List\n",
    "        the list of descriptors that need to be deleted\n",
    "    =========\n",
    "    \n",
    "    Output: a filtered data frame containing descriptors\n",
    "    '''\n",
    "    \n",
    "    if len(feature_list) == 0:\n",
    "        return remove_list\n",
    "\n",
    "    for f in df[feature][df[feature]>=threshold].index:\n",
    "        if f != feature and f not in remove_list:\n",
    "            remove_list.append(f)\n",
    "\n",
    "    feature_list.remove(feature)\n",
    "\n",
    "    df.drop(index=feature, inplace=True)\n",
    "    if len(df) != 0:\n",
    "        feature = df[feature][df[feature]==min(df[feature])].index[0]\n",
    "\n",
    "    return get_removed_correlation(df, feature_list, feature, threshold, remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_features(input_filename, std_threshold, r_threshold, output_filename):\n",
    "    '''\n",
    "    This function is to filter descriptors for training dataset\n",
    "    =========\n",
    "    Parameter:\n",
    "    \n",
    "    input_filename: String\n",
    "        input file name\n",
    "    \n",
    "    std_threshold: float\n",
    "        the threshold of filtering by std\n",
    "    \n",
    "    r_threshold: float\n",
    "        the threshold of filtering by Pearson correlation\n",
    "    \n",
    "    output_filename: String\n",
    "        output file name\n",
    "    =========\n",
    "    '''\n",
    "    \n",
    "    data = pd.read_csv(input_filename)\n",
    "    \n",
    "    # get descriptors based on SMILES\n",
    "    data = smiles_descriptors(data)\n",
    "    \n",
    "    # filter descriptors with std\n",
    "    data = filter_std(data, std_threshold)\n",
    "    print(data.shape)\n",
    "    \n",
    "    # filter descriptors with r2\n",
    "    r2_df = data.iloc[:,6:].corr()**2\n",
    "    feature_list = list(r2_df.columns)\n",
    "    start_feature = 'MolLogP'\n",
    "    remove_list = []\n",
    "    remove_list = get_removed_correlation(r2_df, feature_list, start_feature, r_threshold, remove_list)\n",
    "    \n",
    "    data.drop(remove_list, axis=1, inplace=True)\n",
    "    data.sort_values(['rtmed'], inplace=True)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    data.to_csv(output_filename, index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filename = \"combined_training_data.csv\"\n",
    "# output_filename = \"combined_train_with_features.csv\"\n",
    "# std_threshold = 0.01\n",
    "# r_threshold = 0.96\n",
    "# get_training_features(input_filename, std_threshold, r_threshold, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_features(input_filename, output_filename, train_filename):\n",
    "    '''\n",
    "    This function is to get descriptors for validation dataset\n",
    "    =========\n",
    "    Parameter:\n",
    "    \n",
    "    input_filename: String\n",
    "        input file name\n",
    "    \n",
    "    output_filename: String\n",
    "        output file name\n",
    "        \n",
    "    train_filename: String\n",
    "        training data file name\n",
    "    =========\n",
    "    '''\n",
    "    \n",
    "    train_data = pd.read_csv(train_filename)\n",
    "    descriptors = list(train_data.columns[6:])\n",
    "    \n",
    "    data = pd.read_csv(input_filename)\n",
    "    \n",
    "    for desc, func in Descriptors.descList:\n",
    "        if desc in descriptors:\n",
    "            data.loc[:,desc] = data.SMILES.apply(lambda x: func(Chem.MolFromSmiles(x)) if Chem.MolFromSmiles(x) is not None else 'nan')\n",
    "    \n",
    "    data.sort_values(['rtmed'], inplace=True)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    data.to_csv(output_filename, index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filename = \"combined_validation_data.csv\"\n",
    "# output_filename = \"combined_valid_with_features.csv\"\n",
    "# train_filename = \"combined_train_with_features.csv\"\n",
    "# get_validation_features(input_filename, output_filename, train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lipids_features(input_filename, output_filename, train_filename):\n",
    "    '''\n",
    "    This function is to get descriptors for NIST Lipids dataset\n",
    "    =========\n",
    "    Parameter:\n",
    "    \n",
    "    input_filename: String\n",
    "        input file name\n",
    "    \n",
    "    output_filename: String\n",
    "        output file name\n",
    "        \n",
    "    train_filename: String\n",
    "        training data file name\n",
    "    =========\n",
    "    '''\n",
    "    \n",
    "    train_data = pd.read_csv(train_filename)\n",
    "    descriptors = list(train_data.columns[6:])\n",
    "    \n",
    "    data = pd.read_csv(input_filename)\n",
    "    \n",
    "    for desc, func in Descriptors.descList:\n",
    "        if desc in descriptors:\n",
    "            data.loc[:,desc] = data.SMILES.apply(lambda x: func(Chem.MolFromSmiles(x)) if Chem.MolFromSmiles(x) is not None else 'nan')\n",
    "    \n",
    "#     data.sort_values(['rtmed'], inplace=True)\n",
    "#     data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    data.to_csv(output_filename, index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_filename = \"Lipids_NIST_Data.csv\"\n",
    "# output_filename = \"Lipids_NIST_Data_with_features.csv\"\n",
    "# train_filename = \"combined_train_with_features.csv\"\n",
    "# get_lipids_features(input_filename, output_filename, train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lipid_df = pd.read_csv(\"Lipids_NIST_Data_with_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lipid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
